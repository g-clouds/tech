---
layout: default
title: Section 3
nav_order: 4
has_children: true
---


**Section 3: Scaling prototypes into ML models (~18% of the exam)**

**3.1 Building models**

* Choosing ML framework and model architecture.
* Modeling techniques given interpretability requirements.

**3.2 Training models**

* Organizing training data (e.g., tabular, text, speech, images, videos) on Google Cloud (e.g., Cloud Storage, BigQuery).
* Ingestion of various file types (e.g., CSV, JSON, images, Hadoop, databases) into training.
* Training using different SDKs (e.g., Vertex AI custom training, Kubeflow on Google Kubernetes Engine, AutoML, tabular workflows).
* Using distributed training to organize reliable pipelines.
* Hyperparameter tuning.
* Troubleshooting ML model training failures.

**3.3 Choosing appropriate hardware for training**

* Evaluation of compute and accelerator options (e.g., CPU, GPU, TPU, edge devices).
* Distributed training with TPUs and GPUs (e.g., Reduction Server on Vertex AI, Horovod).

---