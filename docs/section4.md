---
layout: default
title: Section 4
nav_order: 5
has_children: true
---


**Section 4: Serving and scaling models (~19% of the exam)**

**4.1 Serving models**

* Batch and online inference (e.g., Vertex AI, Dataflow, BigQuery ML, Dataproc).
* Using different frameworks (e.g., PyTorch, XGBoost) to serve models.
* Organizing a model registry.
* A/B testing different versions of a model.

**4.2 Scaling online model serving**

* Vertex AI Feature Store.
* Vertex AI public and private endpoints.
* Choosing appropriate hardware (e.g., CPU, GPU, TPU, edge).
* Scaling the serving backend based on the throughput (e.g., Vertex AI Prediction, containerized serving).
* Tuning ML models for training and serving in production (e.g., simplification techniques, optimizing the ML solution for increased performance, latency, memory, throughput).

---