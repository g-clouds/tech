---
layout: default
title: Section 6
nav_order: 7
has_children: true
---


**Section 6: Monitoring ML solutions (~14% of the exam)**

**6.1 Identifying risks to ML solutions**

* Building secure ML systems (e.g., protecting against unintentional exploitation of data or models, hacking).
* Aligning with Google's Responsible AI practices (e.g., biases).
* Assessing ML solution readiness (e.g., data bias, fairness).
* Model explainability on Vertex AI (e.g., Vertex AI Prediction).

**6.2 Monitoring, testing, and troubleshooting ML solutions**

* Establishing continuous evaluation metrics (e.g., Vertex AI Model Monitoring, Explainable AI).
* Monitoring for training-serving skew.
* Monitoring for feature attribution drift.
* Monitoring model performance against baselines, simpler models, and across the time dimension.
* Common training and serving errors. 
  
---